{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import dlib\nimport cv2\nimport numpy as np\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport glob\nimport openface\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder\n%matplotlib inline\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "characters \u003d [\u0027sakib\u0027,\u0027manash\u0027,\u0027sourav\u0027]\nface_detector \u003d dlib.get_frontal_face_detector()\nface_recognition_model \u003d \u0027./data/model/dlib_face_recognition_resnet_model_v1.dat\u0027\nface_pose_predictor \u003d dlib.shape_predictor(\u0027./data/model/shape_predictor_68_face_landmarks.dat\u0027)\nface_encoder \u003d dlib.face_recognition_model_v1(face_recognition_model)\ndf \u003d pd.DataFrame()\n\nfor char in characters:\n    l \u003d []\n    for filename in glob.glob(\u0027./data/train/%s/*\u0027 % char):\n        image \u003d cv2.imread(filename)\n        image \u003d cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        detected_faces \u003d face_detector(image, 1)\n        face_detect \u003d detected_faces[0]\n        pose_landmarks \u003d face_pose_predictor(image, face_detect)\n        face_encoding \u003d np.array(face_encoder.compute_face_descriptor(image, pose_landmarks, 1))\n        l.append(np.append(face_encoding, [char]))\n    \n    temp \u003d pd.DataFrame(np.array(l))\n    df \u003d pd.concat([df, temp])\n\ndf.reset_index(drop\u003dTrue, inplace\u003dTrue)\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Training for 3 classes.\n128 columns for X\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "le \u003d LabelEncoder()\ny \u003d le.fit_transform(df[128])\nprint(\"Training for {} classes.\".format(len(le.classes_)))\nX \u003d df.drop(128, axis\u003d1)\nprint(\u0027{} columns for X\u0027.format(len(X.columns)))\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "data": {
            "text/plain": "SVC(C\u003d1, cache_size\u003d200, class_weight\u003dNone, coef0\u003d0.0,\n  decision_function_shape\u003d\u0027ovr\u0027, degree\u003d3, gamma\u003d\u0027auto_deprecated\u0027,\n  kernel\u003d\u0027linear\u0027, max_iter\u003d-1, probability\u003dTrue, random_state\u003dNone,\n  shrinking\u003dTrue, tol\u003d0.001, verbose\u003dFalse)"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 5
        }
      ],
      "source": "clf \u003d SVC(C\u003d1, kernel\u003d\u0027linear\u0027, probability\u003dTrue)\nclf.fit(X, y)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[[0.01536182 0.04858833 0.93604985]]\n[[0.01536182 0.04858833 0.93604985]]\n"
          ],
          "output_type": "stream"
        },
        {
          "evalue": "bad input shape ()",
          "ename": "ValueError",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-13-f5d50421d2dc\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 14\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#cv2.putText(img, y_pred, (face_detect.left(), face_detect.top()-5), font, 0.9, (255, 0, 0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.virtualenvs/FaceRecognition/lib/python3.5/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[1;32m    272\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\u0027classes_\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 273\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.virtualenvs/FaceRecognition/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape ()"
          ],
          "output_type": "error"
        }
      ],
      "source": "font \u003d cv2.FONT_HERSHEY_SIMPLEX\nimage \u003d cv2.imread(\u0027./data/test/6.jpg\u0027)\nimage \u003d cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimg \u003d np.copy(image)\ndetected_faces \u003d face_detector(image, 1)\nfor face_detect in detected_faces:\n    cv2.rectangle(img, (face_detect.left(), face_detect.top()), (face_detect.right(), face_detect.bottom()), (255, 0, 0), 2)\n    pose_landmarks \u003d face_pose_predictor(image, face_detect)\n    face_encoding \u003d np.array(face_encoder.compute_face_descriptor(image, pose_landmarks, 1))\n    p \u003d clf.predict_proba(face_encoding.reshape(1, 128))\n    print(p)\n    if np.max(p) \u003e 0.8:\n        print(p)\n        y_pred \u003d le.inverse_transform(np.argmax(p))\n        cv2.putText(img, y_pred, (face_detect.left(), face_detect.top()-5), font, 0.9, (255, 0, 0))\nplt.figure(figsize\u003d(20,10))\nplt.imshow(img)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (FaceRecognition)",
      "language": "python",
      "name": "pycharm-d1ca6ab9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}